{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ran_data(n_stock,n_period,n_feat):\n",
    "    \n",
    "    X = np.vstack([np.vstack([np.random.permutation(np.linspace(-1,1,n_stock)) for _ in range(n_feat)]).T for n in range(n_period)])\n",
    "    cols=[f\"f{_}\" for _ in range(n_feat)]\n",
    "    sample_df=pd.DataFrame(X,columns=cols)\n",
    "    dates = pd.date_range('2000-01-01', periods=n_period, freq='MS')\n",
    "    sample_df[\"date\"] = [date for date in dates for _ in range(n_stock)]\n",
    "    sample_df[\"PERMNO\"] = list(range(n_stock))*n_period\n",
    "    sample_df[\"ret\"] = np.random.randn(n_stock*n_period)\n",
    "    sample_df[\"weight\"] = np.random.rand(n_stock*n_period)\n",
    "    sample_df[\"weight\"] = sample_df[\"weight\"]/sample_df.groupby(\"date\")[\"weight\"].transform(\"sum\")\n",
    "    \n",
    "    return sample_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sharpe(X):\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    X = X.values.reshape(n, -1) #reshape to 2d array in case X is 1d\n",
    "    y = np.ones(n)\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    residuals = y - X @ beta\n",
    "    rss = np.sum(residuals**2)\n",
    "    sr =  (n / rss - 1)**0.5\n",
    "    \n",
    "    return sr\n",
    "\n",
    "def filter_panel_by_to_node(node_ind,sample_df,max_node):\n",
    "    for parent_node_no in range(max_node):\n",
    "        temp_df=sample_df\n",
    "        if row[f\"node_{parent_node}_parent\"] == \"left\":\n",
    "            temp_df=temp_df[temp_df[f\"split_{parent_node_no}\"]]\n",
    "        elif row[f\"node_{parent_node}_parent\"] == \"right\":\n",
    "            temp_df=temp_df[~temp_df[f\"split_{parent_node_no}\"]]\n",
    "    return temp_df\n",
    "\n",
    "def split_and_gen_factor(node_sample_df,feat,thres,lr):\n",
    "    \n",
    "    if lr == \"left\":\n",
    "        new_df=node_sample_df[node_sample_df[feat]>=thres][\"ret\",\"weight\"]\n",
    "    elif lr == \"right\":\n",
    "        new_df=node_sample_df[node_sample_df[feat]<thres][\"ret\",\"weight\"]\n",
    "    new_factor=new_df.groupby(\"date\").apply(lambda x: x[\"ret\"] * x[\"weight\"]/x[\"weight\"].sum()).sum()\n",
    "    \n",
    "    return new_factor\n",
    "\n",
    "def gen_tree(sample_df,n_period,n_stock,n_feat,thres_list,max_node):\n",
    "    tree_df=pd.DataFrame([[999,999,True]+[\"Irr\"]*max_node], columns=[\"char\",\"thres\",\"leaf\"]+[f\"node_{i}_parent\" for i in range(max_node)])\n",
    "    factor_df=pd.DataFrame()\n",
    "    feat_list=[f\"f{_}\" for _ in range(n_feat)]\n",
    "    log_df=pd.DataFrame()\n",
    "    for split in range(max_node-1):\n",
    "        for ind,row in tree_df[tree_df[\"leaf\"]].iterrows():\n",
    "            node_sample_df=filter_panel_by_to_node(node_ind,sample_df,max_node)\n",
    "            for feat in feat_list:\n",
    "                for thres in thres_list:\n",
    "                        left_factor=split_and_gen_factor(node_sample_df,feat,thres,\"left\")\n",
    "                        right_factor=split_and_gen_factor(node_sample_df,feat,thres,\"right\")\n",
    "                        sr=Sharpe(pd.concat([left_factor,right_factor,factor_df],axis=1))\n",
    "                        log_df=log_df.append({\"char\":feat,\"thres\":thres,\"split\":split,\"node\":ind,\"sr\":sr},ignore_index=True)\n",
    "                        \n",
    "        best_split=log_df[(log_df[\"split\"]==split)]\n",
    "        best_split=best_split[(best_split[\"sr\"]==best_split[\"sr\"].max())].iloc[0]\n",
    "        \n",
    "        new_left_node={\"char\":best_split[\"char\"],\"thres\":best_split[\"thres\"],\"leaf\":True}\n",
    "        new_left_node.update(tree_df[best_split[\"node\"]][[f\"node_{i}_parent\" for i in range(max_node)]].to_dict())\n",
    "        new_left_node.update({f\"node_{best_split['node']}_parent\":\"left\"})\n",
    "        tree_df.append(new_left_node,ignore_index=True)\n",
    "        \n",
    "        new_right_node={\"char\":best_split[\"char\"],\"thres\":best_split[\"thres\"],\"leaf\":True}\n",
    "        new_right_node.update(tree_df[best_split[\"node\"]][[f\"node_{i}_parent\" for i in range(max_node)]].to_dict())\n",
    "        new_right_node.update({f\"node_{best_split['node']}_parent\":\"right\"})\n",
    "        tree_df.append(new_right_node,ignore_index=True)\n",
    "        \n",
    "        tree_df.loc[best_split,\"leaf\"]=False\n",
    "        new_left_panel=filter_panel_by_to_node(new_left_node,sample_df,max_node)\n",
    "        new_left_factor=split_and_gen_factor(new_left_panel,new_left_node[\"char\"],new_left_node[\"thres\"],\"left\")\n",
    "        factor_df[best_split[\"ind\"]+1]=new_left_factor\n",
    "        new_right_panel=filter_panel_by_to_node(new_right_node,sample_df,max_node)\n",
    "        new_right_factor=split_and_gen_factor(new_right_panel,new_right_node[\"char\"],new_right_node[\"thres\"],\"right\")      \n",
    "        factor_df[best_split[\"ind\"]+2]=new_left_factor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5,  0. ],\n",
       "       [ 0. , -1. ],\n",
       "       [ 1. , -0.5],\n",
       "       [ 0.5,  1. ],\n",
       "       [-1. ,  0.5],\n",
       "       [ 1. , -1. ],\n",
       "       [ 0.5,  0.5],\n",
       "       [ 0. , -0.5],\n",
       "       [-1. ,  1. ],\n",
       "       [-0.5,  0. ],\n",
       "       [-0.5, -1. ],\n",
       "       [ 1. ,  0. ],\n",
       "       [ 0.5,  1. ],\n",
       "       [-1. , -0.5],\n",
       "       [ 0. ,  0.5],\n",
       "       [ 0. ,  0. ],\n",
       "       [ 0.5, -0.5],\n",
       "       [-1. ,  0.5],\n",
       "       [-0.5, -1. ],\n",
       "       [ 1. ,  1. ],\n",
       "       [ 0. ,  0.5],\n",
       "       [-1. , -1. ],\n",
       "       [ 0.5,  1. ],\n",
       "       [ 1. ,  0. ],\n",
       "       [-0.5, -0.5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    X = [np.stack([np.random.permutation(np.linspace(-1,1,5)).T for _ in range(5)],axis=0) for p in range(2)]\n",
    "    X = np.block(X).T\n",
    "    X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. , -0.5,  0.5, -1. ,  1. ],\n",
       "       [-1. ,  0.5,  0. ,  0. , -1. ],\n",
       "       [ 0. , -1. , -1. , -0.5,  0. ],\n",
       "       [-0.5,  0. , -0.5,  1. , -0.5],\n",
       "       [ 0.5,  1. ,  1. ,  0.5,  0.5],\n",
       "       [ 0.5, -0.5, -0.5,  0.5, -1. ],\n",
       "       [ 0. ,  0. , -1. , -0.5, -0.5],\n",
       "       [-0.5,  0.5,  1. , -1. ,  1. ],\n",
       "       [-1. , -1. ,  0.5,  0. ,  0. ],\n",
       "       [ 1. ,  1. ,  0. ,  1. ,  0.5]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([np.vstack([np.random.permutation(np.linspace(-1,1,5)) for _ in range(5)]).T for n in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loss_weight(sample_df):\n",
    "    \n",
    "    weights=sample_df.groupby([\"date\"])[\"RET\"].count()\n",
    "    weights=1/weights\n",
    "    weights.rename(\"loss_weight\",inplace=True)\n",
    "    sample_df=pd.merge(left=sample_df,right=weights,left_on=\"date\",right_index=True,how=\"left\",validate=\"m:1\")\n",
    "    \n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"/mnt/work/hc2235/Panel_Tree_replication/data_preparation/output/weighted_trainp.csv\",index_col=0)\n",
    "train_df.drop(columns=[\"loss_weight\"],inplace=True)\n",
    "train_df.to_csv(\"/mnt/work/hc2235/Panel_Tree_replication/data_preparation/output/weighted_trainp.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pandas as pd\n",
    "    import os\n",
    "    os.curdir=\"/mnt/work/hc2235/Panel_Tree_replication/data_preparation/code\"\n",
    "    train_df=pd.read_csv(os.path.join(\"/mnt/work/hc2235/Panel_Tree_replication/data_preparation/output\",\"weighted_trainp_loss_weight.csv\"),index_col=0)\n",
    "    test_df=pd.read_csv(os.path.join(\"/mnt/work/hc2235/Panel_Tree_replication/data_preparation/output\",\"weighted_testp_loss_weight.csv\"),index_col=0)\n",
    "    \n",
    "    train_df_toy=train_df.drop(columns=[f\"f{_}\" for _ in range(4,51)])\n",
    "    test_df_toy=test_df.drop(columns=[f\"f{_}\" for _ in range(4,51)])\n",
    "    \n",
    "    train_df_toy.to_csv(os.path.join(\"/mnt/work/hc2235/Panel_Tree_replication/test_sample_generation\",\"weighted_trainp_loss_weight_toy.csv\"))\n",
    "    test_df_toy.to_csv(os.path.join(\"/mnt/work/hc2235/Panel_Tree_replication/test_sample_generation\",\"weighted_testp_loss_weight_toy.csv\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitattributes',\n",
       " '.gitignore.txt',\n",
       " 'LICENSE',\n",
       " 'data_preparation',\n",
       " 'grow_tree',\n",
       " 'raw_data',\n",
       " 'table_preparation',\n",
       " 'test_sample_generation',\n",
       " '.gitignore',\n",
       " 'README.md',\n",
       " 'master_script.sh']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(\"/mnt/work/hc2235/Panel_Tree_replication/data_preparation/output/weighted_testp.csv\",index_col=0)\n",
    "test_df=add_loss_weight(test_df)\n",
    "test_df.to_csv(\"/mnt/work/hc2235/Panel_Tree_replication/data_preparation/output/weighted_testp_loss_weight.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
